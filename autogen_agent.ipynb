{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opniBQOmnXp9"
      },
      "source": [
        "**This notebook needs to run on local device.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Kmrd1yFhFkVd",
        "outputId": "b83daf10-b73a-48b7-ffc9-db47982e2f84"
      },
      "outputs": [],
      "source": [
        "# ! pip -q install pyautogen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ10pFmhhUsh"
      },
      "outputs": [],
      "source": [
        "import autogen\n",
        "\n",
        "config_list = [\n",
        "    {\n",
        "        'model': 'openai',\n",
        "        'base_url': 'http://localhost:1234/v1', # replace it with your endpoint. In this case I have used https://lmstudio.ai/\n",
        "        'api_key': 'lm-studio'\n",
        "    }\n",
        "]\n",
        "\n",
        "llm_config={\n",
        "    'timeout': 600,\n",
        "    'cache_seed': 44,\n",
        "    'config_list': config_list,\n",
        "    'temperature': 0\n",
        "}\n",
        "\n",
        "# create an AssistantAgent instance named \"assistant\"\n",
        "assistant = autogen.AssistantAgent(\n",
        "    name=\"assistant\",\n",
        "    llm_config=llm_config,\n",
        "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
        "    system_message=\"you are an experienced python developer.\"\n",
        ")\n",
        "\n",
        "# create a UserProxyAgent instance named \"user_proxy\"\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
        "    max_consecutive_auto_reply=10,\n",
        "    code_execution_config={\n",
        "        \"work_dir\": \"work_dir\",\n",
        "        \"use_docker\": False,\n",
        "    },\n",
        ")\n",
        "\n",
        "task = \"write a python file to output numbers from 1 to 10\"\n",
        "\n",
        "user_proxy.initiate_chat(assistant, message=task)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
