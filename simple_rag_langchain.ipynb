{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<imports>\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "#<\\imports>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<get hf token>\n",
    "HF_TOKEN = getpass(\"Huggingface Token : \")\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HF_TOKEN\n",
    "#<\\get hf token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<load document>\n",
    "loader = PyPDFLoader(\"data/sample_data.pdf\")\n",
    "data = loader.load()\n",
    "#<\\load document>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<make chunks>\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 512,chunk_overlap = 0)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "#<\\make chunks>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<make embeddings>\n",
    "model_name = \"thenlper/gte-large\"\n",
    "embedding_model = FastEmbedEmbeddings(model_name=model_name)\n",
    "#<\\make embeddings>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<make chroma db>\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db\")\n",
    "#<make chroma db>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<define query that is used multiple times>\n",
    "query = \"what happens if I sell my dreams?\"\n",
    "#<\\define query that is used multiple times>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<retrieve docs>\n",
    "db2 = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_model)\n",
    "retrieved_docs = db2.similarity_search(query)\n",
    "print(retrieved_docs[0].page_content)\n",
    "#<\\retrieve docs>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<initialize retriever>\n",
    "retriever = db2.as_retriever(\n",
    "    search_type=\"mmr\", #similarity\n",
    "    search_kwargs={'k': 4}\n",
    "    )\n",
    "#<\\initialize retriever>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<define llm>\n",
    "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "                     model_kwargs={\n",
    "                         \"temperature\":0.1,\n",
    "                         \"max_new_tokens\":512,\n",
    "                         \"return_full_text\":False,\n",
    "                         \"repetition_penalty\":1.1,\n",
    "                         \"top_p\":0.9\n",
    "                         }\n",
    "                    )\n",
    "#<\\define llm>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<define chain components and chain>\n",
    "#template\n",
    "template = \"\"\"\n",
    "<s>[INST]\n",
    "You are an AI Assistant that follows instructions extremely well.\n",
    "Please be truthful and give direct answers. Please tell 'I don't know' if user query is not in CONTEXT\n",
    "[/INST]\n",
    "CONTEXT: {context}\n",
    "</s>\n",
    "[INST]\n",
    "{query}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "#prompt\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "#output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "#chain\n",
    "chain = (\n",
    "{\"context\": retriever, \"query\": RunnablePassthrough()}\n",
    "| prompt\n",
    "| llm\n",
    "| output_parser\n",
    ")\n",
    "\n",
    "#<\\define chain components and chain>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<test response>\n",
    "response = chain.invoke(query)\n",
    "response\n",
    "#<\\test response>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = chain.invoke(\"what is the authors name?\")\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = chain.invoke(\"For how many years does the author tell the lady to leave right away and not come back to Vienna\")\n",
    "response3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragamuffin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
