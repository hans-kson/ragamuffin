{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<imports>\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "#<\\imports>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<get hf token>\n",
    "HF_TOKEN = getpass(\"Huggingface Token : \")\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HF_TOKEN\n",
    "#<\\get hf token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<load docs and split to chunks>\n",
    "loader = PyPDFDirectoryLoader('data/')\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "#<\\load docs and split to chunks>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<prompt template>\n",
    "prompt_template = \"\"\"\n",
    "<|system|>\n",
    "You are an AI Assistant that follows instructions extremely well.\n",
    "Please be truthful and give direct answers. Please tell 'I don't know' if user query is not in CONTEXT\n",
    "\n",
    "CONTEXT: {context}\n",
    "</s>\n",
    "<|user|>\n",
    "{query}\n",
    "</s>\n",
    "<|assistant|>\n",
    "Your answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "#<\\prompt template>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<init embeddings and vec store>\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")\n",
    "vectorstore = Chroma.from_documents(chunks, embeddings)\n",
    "\n",
    "query = \"what is electrolysis\"\n",
    "search = vectorstore.similarity_search(query)\n",
    "#<\\init embeddings and vec store>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<create bm25 and vector retrievers>\n",
    "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "vector_retriever = vectorstore.as_retriever()\n",
    "#\\<create bm25 and vector retrievers>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<set up ensemble retriever>\n",
    "retrievers = [bm25_retriever, vector_retriever]\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=retrievers, weights=[0.5, 0.5])\n",
    "#<\\set up ensemble retriever>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<init llm>\n",
    "llm = HuggingFaceHub(repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "                     task=\"text-generation\",\n",
    "                     model_kwargs={\n",
    "                         \"max_new_tokens\": 512,\n",
    "                         \"top_k\": 30,\n",
    "                         \"temperature\": 0.1,\n",
    "                         \"repetition_penalty\": 1.1,\n",
    "                         \"return_full_text\":False\n",
    "                         },\n",
    "                    )\n",
    "#<\\init llm>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<make rag pipe>\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "retriever= ensemble_retriever\n",
    "chain = (\n",
    "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "#<\\make rag pipe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<test query>\n",
    "query = \"what is an electrolyte\"\n",
    "response = chain.invoke(query)\n",
    "print(response)\n",
    "\n",
    "print(chain.invoke(\"what is electrolysis?\"))\n",
    "\n",
    "print(chain.invoke(\"why do we dream?\"))\n",
    "#<\\test query>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragamuffin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
